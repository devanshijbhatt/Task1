{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## List of models who have issues in storage or tokens"
      ],
      "metadata": {
        "id": "eeRR0IMcmRxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/HuggingFaceH4/starchat-alpha\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you generate 5 titles related to this paragraph: 5.\tHimachal Pradesh, one of the worst hit states by the monsoon fury this year, is calling tourists back to lustrous green mountains. To woo back tourists who are largely avoiding travel to the state amid heavy rains, the Himachal Pradesh hotel association has announced a 50 per cent discount on room tariffs.Flash floods and landslides caused by heavy downpour in the state has claimed 187 lives since the onset of the Monsoon in the state on June 24. The hotel occupancy rate in Himachal is at almost zero per cent after the recent monsoon fury.Now, Himachal's Public Works Minister Vikramaditya Singh has also called on tourists to return and said the situation is becoming normal and Himachal is safe to travel now.Himachs Tourism IndustryThe tourism industry in Himachal Pradesh has been badly hit due to heavy rains this year. The National Highway from Dharamshala to Mcleodganj is severely damaged in several places. A loss of more than Rs 6 crore has been estimated due to rains in Dharamshala only which may increase further as reports are yet to come from many departments.The tourism industry was recovering after the COVID-19 pandemic and recorded one crore six thousand tourist footfalls in the first half of 2023, but the havoc wreaked by heavy rains and floods during the month of July resulted in negligible tourist footfall, and thousands of bookings were canceled.Road To RecoveryThe monsoon is a lean tourist season and the occupancy rate falls to 30 to 40 per cent but this time hotels are empty. Not only private hotels are offering huge discounts, but the Himachal Pradesh Tourism Development Corporation has also announced a 50 per cent discount on room rents till September 15.The hotel industry has announced a 50 per cent discount to tourists and roads are being restored and there is nothing to worry, Federation of Himachal Hotels and Restaurant Associations president Ashwani Bamba told news agency PTI on Saturday Safe To Travel. We are hoping that the tourist inflow will gradually increase by September. In a video released here on Saturday, Public Works Minister Vikramaditya Singh said that the situation is becoming normal and Himachal is safe to travel now. I assure tourists that things are coming back to normal and Himachal Pradesh is safe to travel now. You can come to enjoy the natural beauty of the state and the government would make all efforts to ensure that your stay is safe and all facilities are provided to you, he said in a video.Relief And Rescue Ops In StateThe state government had safely evacuated about 75,000 tourists from different parts of the state recently.Videos of landslides blocking roads, tourists stranded, floods damaging buildings, sweeping vehicles and roads caving in causing enormous damage to life and property had gone viral since July 9 and as a result the tourists are apprehensive to travel to the hill state during the ongoing monsoon.So far, 184 persons have died in rain-related incidents and road accidents since June 24 when the monsoon hit the state.Thirty-three people are missing as per the state emergency response centre.(With Inputs from ANI PTI)\",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXyeQ5_s33pO",
        "outputId": "f773bbc9-6ee0-4a0c-ffc0-d5010d969810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model HuggingFaceH4/starchat-alpha is too large to be loaded automatically (31GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/google/flan-t5-xxl\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you generate title related to this:One mention of Barbie and you instantly think of a lean, tall-figured doll who is always well-dressed and has a perfect life. This stereotype is stuck with the doll for years, despite the numerous new designs and models being introduced. Director Greta Gerwig understood these stereotypes and even plays along with them for the first 15 to 20 minutes of the Barbie movie. However, she shatters the glass as soon as she is done playing with the doll and gets down to business to tell a relatable, feminist, and applaud-worthy movie that lives up to the hype. Barbie, starring Margot Robbie in the lead, is set in Barbie Land which has several kinds of Barbies co-existing. We see the stereotype Barbie (Margot), the President Barbie (Issa Rae), Physicist Barbie (Emma Mackey), and Lawyer Barbie (Sharon Rooney), among many more, running the Barbie land while the men, all of them named Ken, double up as their supporters, lovers, and partners. All goes well in the alter imaginary world until one day, the stereotypical Barbie wakes up feeling unusual emotions. She begins to wonder about death, loses her ability to walk on her toes, and exhibits sad emotions. When she approaches the Weird Barbie (Kate McKinnon), she learns that a portal between Barbie Land and the real world has led to Barbie feeling human-like emotions. She is advised to visit the real world to find answers. Driving through roads, crossing mountains and seas, Barbie and Ken (Ryan Gosling) roller-blade into Venice Beach in California where they meet Gloria (America Ferrera) and her daughter Sasha (Ariana Greenblatt). While Gloria is still a fan of Barbie, Sasha is not on board with the idea of Barbie and even calls her a fascist on her face. Barbie soon understands that her questions are being answered but Ken goes off on a different journey of self-discovery. He learns that in the real world, men are treated higher than women and that the concept of patriarchy plays to their benefit. Ken returns to Barbie Land and brings about drastic changes. On the other hand, Barbie also lands in her own world with the mother-daughter duo and finds out everything is changing. This leaves her worried. How will Barbie save her world? I recommend you watch the film and find out. Greta, with co-writer Noah Baumbach, delivers a colourful, fresh, and probably one of the best concepts of the year. While the film starts off as though it is portraying a delusional world of Barbies, Greta smashes open the plot and lets you in on her feminist take on the popular doll. She is conveying some of the most powerful messages with the film, she is doing it under the garb of humour and coming-of-age, making the impact stronger. The dialogues and screenplay are the biggest superpowers of Barbie. Greta makes several pop culture references thus adopting the meta narration which helps Barbie take things a notch higher. She also takes digs at Margot Robbie, the concept of Barbie over the years, Warner Bros projects, and patriarchy, leaving everyone in splits. Barbie is so strong in its approach towards surprise humour that it somewhat reminded me of Phoebe Waller-Bridges style of comedy. On the acting front, Margot proves she was meant to play the role of Barbie. The actress shifts gears from being the happy-go-lucky Barbie to the Barbie no one has ever seen before with utmost ease. However, Ryan Gosling steals the show. He channels his inner Kenergy so hard that he outshines Margot in a few scenes. He also shows his comedy side in the goofiest way possible. His rapport with Simu Liu in the film, especially in their musical scenes, is hilarious and you will find yourself asking for more of their scenes. America Ferrera also holds the screen in the film. Her monologue in the film was not only relatable but also very moving. That scene and her performance will be discussed in the days to come. However, she couldn't match up to Margot and Ryan's massive energy in the film. Kate McKinnon as Weird Barbie also knows how to hold the camera's attention but is outshined by Margot. However, Barbie has its share of flaws as well. The climax is based on convenience and shifts focus from Barbie to Ken, which backfires the whole build-up of the film. To top it off, it appeared as though Greta was confused about how to end the film so she brought in a strange subplot to wrap things off, paving the way to several questions but no answers. Bottom Line: Dear Barbies, take your Kens with you to watch the impressive Gret Gerwig directorial because the film talks about the various struggles women go through that men truly need to be reminded of. Watch the film for the dialogue writing and Margot and Ryan's performances.\",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0MHmsqR4tHw",
        "outputId": "d7e13ae3-e42c-4226-9e34-e409f780d967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'Input validation error: `inputs` must have less than 1024 tokens. Given: 1137', 'error_type': 'validation'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/geobrain-ai/geogalactica\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"write 10 sentences on Apple\",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se_NxmFmjMni",
        "outputId": "467b2a53-eda6-4d45-f993-3b507a99a5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model geobrain-ai/geogalactica is too large to be loaded automatically (121GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"write 10 sentences on Apple\",\n",
        "})\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLmj1X-JqfJA",
        "outputId": "0cf06df8-ce6d-41f8-9766-de75f6445b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-hf\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNnsJ1sarS8h",
        "outputId": "b1c85617-3123-4d9b-9cb7-2189a70dd6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aB__2r8ugpY",
        "outputId": "983231ed-b2fe-4c99-f4cb-af1ea67baf52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"microsoft/phi-2\")"
      ],
      "metadata": {
        "id": "6NrFV0cMs66R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "torch.set_default_device(\"cuda\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
        "\n",
        "inputs = tokenizer('''def print_prime(n):\n",
        "   \"\"\"\n",
        "   Print all primes between 1 and n\n",
        "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=200)\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text)"
      ],
      "metadata": {
        "id": "l7ZpSjnrDp14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/whiterabbitneo/WhiteRabbitNeo-13B\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3BIizjCvwl9",
        "outputId": "00ee382f-8543-41ca-b8b7-0f2c82e9d614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model whiterabbitneo/WhiteRabbitNeo-13B is too large to be loaded automatically (26GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvDjpit9FUW6",
        "outputId": "e30c2f28-4c7e-49ef-b8c6-dedc479903ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.0-py3-none-any.whl (270 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/270.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/270.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m266.2/270.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.7/270.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please suggest one sentence summary of this paragraph:Indian woman, Anju who travelled to Pakistan to meet and marry her lover Nasrullah, was gifted a piece of land, Pakistan Rs 50,000 and other gifts by a Pakistani businessman. Mohsin Khan Abbasi, CEO of Pak Star Group of Companies gave her gifts as an encouragement for converting to Islam.Abbasi said that his intention is to ensure that Anju faces no issues and feels at home in Pakistan. He said that his company decided to provide a plot of 272 square feet to Anju to build a house, an India Today report said. Another thing is when someone comes to a new place, the main problem is housing. Since we have a project running, we thought we can accomodate them here. Our board of directors approved it and we the plot in her name, Abbasi was heard saying in a video.Anju received 10 Marla housing land,cheque of 50K, other Gifts, given by Islamabad Based businessman CEO of Pak Star Group of Companies Mohsin Khan Abbasi. CEO PSG said that, Anju has converted to Islam and married Nasrullah,so we are welcoming her. #AnjuNasrullahLoveStory pic.twitter.com/22j5CWM9LCâ€” Ghulam Abbas Shah (@ghulamabbasshah) July 29, 2023Abbasi further urged other businessmen, Pakistani government and the people of the country to support the newly married couple, Nasrullah and Fatima. He said that it is important to make Pakistan feel like home for her, adding that, she should feel valued after she left her home and family in India to marry Nasrullah and embrace Islam.Following her travel to Pakistan, Anju's husband Arvind Kumar said that they are not divorced yet and so she cannot get married there.She claimed that she submitted divorce papers three years ago in Delhi but no such notice has reached him yet, he said.On papers, she is still my wife. She cannot marry anyone else. The government should get the matter investigated, Arvind Kumar added.Anju's father, Gaya Prasad Thomas said that she is mentally disturbed and eccentric. He said that although she is free of nature, she would never get involved in anything like this.The 34-year-old Anju, born in Kailor village in Uttar Pradesh was a resident of Alwar district. She became friends with the 29-year-old Pakistani national, Nasrullah on Facebook in 2019.She travelled via te Wagah-Attari border to a remote village in the tribal province of Khyber Pakhtunkhwa on a valid Pakistani visa to meet Nasrullah.ALSO READ | Indian Woman Anju is Now Pak's Fatima As She Weds Facebook Friend in Peshawar, Converts to IslamA mother of two children, Anju married Nasrullah after converting to Islam on July 25. A senior officer at Moharrar City Police Station in Upper district had said that Nasrullah and Anju's marriage was solemnised and a proper nikah was performed after she converted to Islam.(With inputs from PTI) \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETftITraFG7K",
        "outputId": "416c10ce-2fa3-4064-f7a7-30e23713ac9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'Internal Server Error'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/stanford-oval/Llama-2-7b-WikiChat\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbXZQ6Iu4c-U",
        "outputId": "35b21baa-7aef-441a-e1cc-6b4d4644b117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model stanford-oval/Llama-2-7b-WikiChat is too large to be loaded automatically (13GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/andreaskoepf/falcon-40b-megacode2\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqx2HdO_MgMT",
        "outputId": "d4102adf-3b5b-401e-8be2-ea1423201aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model andreaskoepf/falcon-40b-megacode2 is too large to be loaded automatically (82GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwwaVi_FPh2D",
        "outputId": "d6b79498-ec34-4a83-8696-23dfe1730637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (17.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/HuggingFaceH4/starchat-alpha\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZHRWLWFn4gi",
        "outputId": "0849efe0-c2c4-44d9-b2d4-45cb667d301a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model HuggingFaceH4/starchat-alpha is too large to be loaded automatically (31GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/dgarage/NameMatching-HuggingFaceH4-zephyr-7b-alpha\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i28tA1wYovY8",
        "outputId": "4ff5447e-d379-419c-fac7-222a492e1065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model dgarage/NameMatching-HuggingFaceH4-zephyr-7b-alpha is too large to be loaded automatically (14GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/Phind/Phind-CodeLlama-34B-v2\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf55TaXjBieQ",
        "outputId": "7837115e-217c-4ec1-c7fb-624b83c31b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model Phind/Phind-CodeLlama-34B-v2 is too large to be loaded automatically (67GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/microsoft/Orca-2-7b\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "id": "FuzC92awL9pM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f7b5db-401b-4dd3-eef6-3cbbbc52d8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model microsoft/Orca-2-7b is too large to be loaded automatically (26GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/h2oai/h2ogpt-16k-codellama-7b\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "id": "602t27vGLvhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386446d2-ae32-48f3-891c-ded14acde5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model h2oai/h2ogpt-16k-codellama-7b is too large to be loaded automatically (13GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you suggest 5 titles for this paragraph: 3.\tKartik Aaryan, who is gearing up for the release of SatyaPrem Ki Katha, has once again sent his fans into a meltdown with his down-to-earth gesture. Kartik, the owner of multiple luxury cars including Lamborghini Urus Capsule, ditched first class to fly in economy during his recent travel. A video has been shared on an Instagram page showing the Bhool Bhulaiyaa 2 actor making his way to his seat. In the video, Kartik was seen wearing a light blue shirt paired with denim. It isn't clear when and on which flight he was on board. Watch the video below:  View this post on InstagramA post shared by Instant Bollywood (@instantbollywood)This isn't the first time a Bollywood star has been spotted travelling economy. In April, Kriti Sanon chose to travel in the economy class. She was, in fact, seen interacting with her fellow passengers. In December last year, News18.com gained access to an exclusive video showing Katrina Kaif and Vicky Kaushal flying economy.   View this post on InstagramA post shared by Viral Bhayani (@viralbhayani)Meanwhile, Kartik Aaryan will be soon seen in a romantic drama titled Satyaprem Ki Katha alongside Kiara Advani. The film has already created a lot of buzz with its trailer. The trailer dropped earlier this month, gave a glimpse of an intense romantic film in the making. In the film, which reunites hit on-screen pair of Kartik and Kiara a year after Bhool Bhulaiyaa 2, features the duo playing a married couple. However, it doesn't seem that Kiara's character Katha is very happy in the marriage.  View this post on InstagramA post shared by Nadiadwala Grandson (@nadiadwalagrandson)Satyaprem Ki Katha marks a massive collaboration between NGE and Namah Pictures. Interestingly, Sajid Nadiadwala and Shareen Mantri Kedia with Kishor Arora and director Sameer Vidwans won a National Award for their respective feature films. Satyaprem Ki Katha will be released in theaters on 29th June 2023. \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp3CRfzbuMiA",
        "outputId": "e73dc20d-9dc6-489e-f85f-a5a993c7fc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"Can you suggest 5 titles for this paragraph: 3.\\tKartik Aaryan, who is gearing up for the release of SatyaPrem Ki Katha, has once again sent his fans into a meltdown with his down-to-earth gesture. Kartik, the owner of multiple luxury cars including Lamborghini Urus Capsule, ditched first class to fly in economy during his recent travel. A video has been shared on an Instagram page showing the Bhool Bhulaiyaa 2 actor making his way to his seat. In the video, Kartik was seen wearing a light blue shirt paired with denim. It isn't clear when and on which flight he was on board. Watch the video below:  View this post on InstagramA post shared by Instant Bollywood (@instantbollywood)This isn't the first time a Bollywood star has been spotted travelling economy. In April, Kriti Sanon chose to travel in the economy class. She was, in fact, seen interacting with her fellow passengers. In December last year, News18.com gained access to an exclusive video showing Katrina Kaif and Vicky Kaushal flying economy.   View this post on InstagramA post shared by Viral Bhayani (@viralbhayani)Meanwhile, Kartik Aaryan will be soon seen in a romantic drama titled Satyaprem Ki Katha alongside Kiara Advani. The film has already created a lot of buzz with its trailer. The trailer dropped earlier this month, gave a glimpse of an intense romantic film in the making. In the film, which reunites hit on-screen pair of Kartik and Kiara a year after Bhool Bhulaiyaa 2, features the duo playing a married couple. However, it doesn't seem that Kiara's character Katha is very happy in the marriage.  View this post on InstagramA post shared by Nadiadwala Grandson (@nadiadwalagrandson)Satyaprem Ki Katha marks a massive collaboration between NGE and Namah Pictures. Interestingly, Sajid Nadiadwala and Shareen Mantri Kedia with Kishor Arora and director Sameer Vidwans won a National Award for their respective feature films. Satyaprem Ki Katha will be released in theaters on 29th June 2023.  View this post on InstagramA post shared by Kartik Aaryan (@kartikaaryan)\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQzfBxm_8VNV",
        "outputId": "5ee7b20c-37a9-4079-b3fb-3b1b8495442d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.0-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.7/270.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/deepseek-ai/deepseek-coder-1.3b-base\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfWWu97Q6AZI",
        "outputId": "524e72b3-9d4a-4d9f-a470-3a0d4d4e814d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'Model deepseek-ai/deepseek-coder-1.3b-base is currently loading', 'estimated_time': 107.72058868408203}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/berkeley-nest/Starling-LM-7B-alpha\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query({\n",
        "\t\"inputs\": \"Can you please let us know more details about your \",\n",
        "})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID6HHogi6u8w",
        "outputId": "ad4b3774-2ad3-45ef-9459-a2ab1bd713b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'The model berkeley-nest/Starling-LM-7B-alpha is too large to be loaded automatically (14GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).'}\n"
          ]
        }
      ]
    }
  ]
}